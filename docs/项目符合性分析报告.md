# 日本陆上养殖项目服务器端符合性分析报告

**分析日期：** 2025-01-XX  
**分析对象：** `/srv/japan_server` 项目  
**对比基准：** 日本陆上养殖数据处理计划文档

---

## 执行摘要

本报告对比分析了 `japan_server` 项目与数据处理计划的符合性，识别出需要改进的关键领域，并提供具体的改进建议。

### 总体评估

- ✅ **架构设计**：模块化设计良好，符合现代开发规范
- ⚠️ **数据模型**：部分字段缺失，需要更新以符合计划要求
- ❌ **数据收集**：缺少数据接收和存储API端点
- ❌ **数据处理**：缺少数据清洗、标准化、质量标记等处理逻辑
- ⚠️ **新表支持**：缺少新创建表的ORM模型

---

## 1. 数据库模型符合性分析

### 1.1 SensorReading 模型

**现状：**
```python
# 当前字段
- id
- sensor_id
- value
- recorded_at
```

**计划要求字段：**
- ✅ `sensor_id` - 已存在
- ✅ `value` - 已存在
- ✅ `recorded_at` - 已存在（但需要补充 `ts_utc` 和 `ts_local`）
- ❌ `batch_id` - **缺失**
- ❌ `pool_id` - **缺失**
- ❌ `ts_utc` - **缺失**（UTC时间戳，毫秒精度）
- ❌ `ts_local` - **缺失**（本地时间戳，日本时区）
- ❌ `metric` - **缺失**（指标名称，如：do, ph, temp等）
- ❌ `type_name` - **缺失**（类型名称）
- ❌ `description` - **缺失**（描述）
- ❌ `unit` - **缺失**（计量单位）
- ❌ `quality_flag` - **缺失**（质量标记：ok/missing/anomaly）
- ❌ `checksum` - **缺失**（完整性校验）
- ❌ `created_at` - **缺失**
- ❌ `updated_at` - **缺失**

**符合度：** 30% ❌

**改进建议：**
1. 更新 `SensorReading` 模型，添加所有缺失字段
2. 注意：数据库表已通过SQL脚本添加了这些字段，但ORM模型未同步更新

---

### 1.2 CameraImage 模型

**现状：**
```python
# 当前字段
- id, camera_id, name, location, status
- image_url, last_update, timestamp
- width, height, format, size, fps
- timestamp_str
```

**计划要求字段：**
- ✅ `camera_id` - 已存在
- ✅ `image_url` - 已存在
- ✅ `width`, `height` - 已存在（但需要补充 `width_px`, `height_px`）
- ✅ `format` - 已存在
- ❌ `batch_id` - **缺失**
- ❌ `pool_id` - **缺失**
- ❌ `ts_utc` - **缺失**（UTC时间戳，毫秒精度）
- ❌ `ts_local` - **缺失**（本地时间戳）
- ❌ `storage_uri` - **缺失**（对象存储路径/URI）
- ❌ `width_px` - **缺失**（宽度像素）
- ❌ `height_px` - **缺失**（高度像素）
- ❌ `codec` - **缺失**（编解码，视频）
- ❌ `quality_flag` - **缺失**（质量标记）
- ❌ `checksum` - **缺失**（完整性校验）

**符合度：** 40% ⚠️

**改进建议：**
1. 更新 `CameraImage` 模型，添加所有缺失字段
2. 数据库表已通过SQL脚本添加了这些字段，需要同步ORM模型

---

### 1.3 ShrimpStats 模型

**现状：**
```python
# 当前字段
- id, uuid, pond_id, input_subdir, output_dir
- created_at_source_iso, created_at_source
- conf, iou, total_live, total_dead
- size_min_cm, size_max_cm, size_mean_cm, size_median_cm
- weight_min_g, weight_max_g, weight_mean_g, weight_median_g
- source_file, created_at, updated_at
```

**计划要求字段：**
- ✅ `pond_id` - 已存在
- ✅ `conf` - 已存在（但需要补充 `confidence_avg`）
- ✅ `total_live` - 已存在（但需要补充 `count`）
- ✅ `size_mean_cm` - 已存在（但需要补充 `avg_length_mm`, `avg_height_mm`）
- ✅ `weight_mean_g` - 已存在（但需要补充 `est_weight_g_avg`）
- ❌ `frame_id` - **缺失**（图像帧ID，FK）
- ❌ `ts_utc` - **缺失**（UTC时间戳，推理时间）
- ❌ `count` - **缺失**（检测数量）
- ❌ `avg_length_mm` - **缺失**（平均长度，毫米）
- ❌ `avg_height_mm` - **缺失**（平均高度，毫米）
- ❌ `est_weight_g_avg` - **缺失**（平均估算体重，克）
- ❌ `feed_present` - **缺失**（是否存在饲料，布尔）
- ❌ `shrimp_shell_present` - **缺失**（是否存在虾皮，布尔）
- ❌ `model_name` - **缺失**（模型名称）
- ❌ `model_version` - **缺失**（模型版本）
- ❌ `confidence_avg` - **缺失**（平均置信度）
- ❌ `notes` - **缺失**（备注）

**符合度：** 35% ⚠️

**改进建议：**
1. 更新 `ShrimpStats` 模型，添加所有缺失字段
2. 数据库表已通过SQL脚本添加了这些字段，需要同步ORM模型

---

### 1.4 新表模型缺失

**计划要求的新表：**
1. ❌ `batches` - **缺少ORM模型**
2. ❌ `feeders_logs` - **缺少ORM模型**
3. ❌ `operations_logs` - **缺少ORM模型**
4. ❌ `manuals_docs` - **缺少ORM模型**
5. ❌ `history_records` - **缺少ORM模型**

**符合度：** 0% ❌

**改进建议：**
1. 创建这5个新表的ORM模型文件
2. 参考数据库DDL脚本中的表结构定义

---

## 2. 数据收集功能符合性分析

### 2.1 传感器数据收集

**计划要求：**
- 设备侧定时采集 → 客户端定时上传 → 服务器接收、清洗、入库
- 支持HTTP/HTTPS POST 或 MQTT 消息队列
- 数据清洗：时间标准化（UTC + 本地时间）、单位统一、异常值检测
- 数据入库：写入 `sensor_readings` 表，记录质量标记、生成完整性校验

**现状：**
- ✅ 有查询服务（`SensorService`）
- ❌ **缺少数据接收API端点**
- ❌ **缺少数据清洗逻辑**
- ❌ **缺少数据标准化处理**
- ❌ **缺少质量标记（quality_flag）设置**
- ❌ **缺少完整性校验（checksum）生成**

**符合度：** 20% ❌

**改进建议：**
1. 创建数据接收API端点：`POST /api/sensors/data`
2. 实现数据清洗服务：时间标准化、单位统一、异常值检测
3. 实现数据质量标记逻辑
4. 实现完整性校验（checksum）生成

---

### 2.2 图像数据收集

**计划要求：**
- 用户触发上传 → 服务器算法推理 → 生成标注与汇总 → 存储与索引
- 支持图像/视频上传
- 元数据提取：时间戳、分辨率、格式、编解码等
- 存储到对象存储，记录URI

**现状：**
- ✅ 有查询服务（`CameraService`）
- ❌ **缺少图像上传API端点**
- ❌ **缺少视频处理逻辑**
- ❌ **缺少元数据提取**
- ❌ **缺少对象存储集成**

**符合度：** 15% ❌

**改进建议：**
1. 创建图像上传API端点：`POST /api/cameras/images`
2. 实现元数据提取服务
3. 集成对象存储（如OSS、S3等）
4. 实现图像检测结果存储逻辑

---

### 2.3 喂食机数据收集

**计划要求：**
- 喂食机自动记录 → 客户端上传 → 服务器接收、清洗、入库
- 存储到 `feeders_logs` 表

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

**改进建议：**
1. 创建 `feeders_logs` 表的ORM模型
2. 创建数据接收API端点：`POST /api/feeders/logs`
3. 实现数据清洗和存储逻辑

---

### 2.4 操作日志收集

**计划要求：**
- 人工录入或系统自动记录 → 服务器接收、清洗、入库
- 存储到 `operations_logs` 表

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

**改进建议：**
1. 创建 `operations_logs` 表的ORM模型
2. 创建数据接收API端点：`POST /api/operations/logs`
3. 实现数据清洗和存储逻辑

---

### 2.5 养殖手册文档收集

**计划要求：**
- 人工上传或批量导入 → 服务器接收、解析、存储
- 支持PDF、Word、Excel等格式
- NLP处理（提取关键信息）
- 存储到 `manuals_docs` 表

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

**改进建议：**
1. 创建 `manuals_docs` 表的ORM模型
2. 创建文档上传API端点：`POST /api/manuals/upload`
3. 实现文档解析服务（PDF、Word、Excel）
4. 实现NLP处理（提取关键信息）

---

### 2.6 历史记录收集

**计划要求：**
- 人工录入或批量导入 → 服务器接收、清洗、入库
- 存储到 `history_records` 表

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

**改进建议：**
1. 创建 `history_records` 表的ORM模型
2. 创建数据接收API端点：`POST /api/history/records`
3. 实现数据清洗和存储逻辑

---

## 3. 数据处理标准符合性分析

### 3.1 数据接收

**计划要求：**
- 接收数据包
- 基本格式校验
- 生成接收时间戳

**现状：**
- ❌ **缺少数据接收端点**
- ❌ **缺少格式校验逻辑**

**符合度：** 0% ❌

---

### 3.2 数据清洗

**计划要求：**
- 时间标准化（UTC + 本地时间）
- 单位统一
- 异常值初步检测

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

**改进建议：**
1. 创建数据清洗服务模块：`services/data_cleaning_service.py`
2. 实现时间标准化函数
3. 实现单位转换函数
4. 实现异常值检测函数

---

### 3.3 数据标准化

**计划要求：**
- 指标名称标准化（metric字段）
- 单位标准化（unit字段）
- 时间格式标准化

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

**改进建议：**
1. 在数据清洗服务中实现标准化逻辑
2. 定义指标名称映射表
3. 定义单位转换表

---

### 3.4 数据存储

**计划要求：**
- 写入数据库表
- 记录质量标记（quality_flag）
- 生成完整性校验（checksum）

**现状：**
- ✅ 有数据库ORM模型
- ❌ **缺少质量标记逻辑**
- ❌ **缺少完整性校验生成**

**符合度：** 30% ⚠️

**改进建议：**
1. 实现质量标记逻辑（根据异常值检测结果）
2. 实现完整性校验生成（如MD5、SHA256等）

---

### 3.5 数据质量管理

**计划要求：**
- 质量指标：完整性、准确性、一致性、及时性
- 质量规则：阈值检查、格式检查、范围检查
- 质量标记：ok/missing/anomaly

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

**改进建议：**
1. 创建数据质量管理服务：`services/data_quality_service.py`
2. 实现质量指标计算
3. 实现质量规则检查
4. 实现质量标记设置

---

## 4. 数据验收流程符合性分析

### 4.1 自动验收

**计划要求：**
- 数据格式校验
- 数据范围校验
- 数据完整性校验
- 质量标记检查

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

---

### 4.2 手动验收

**计划要求：**
- 人工审核界面
- 异常数据标记
- 数据修正流程

**现状：**
- ❌ **完全缺失**

**符合度：** 0% ❌

---

## 5. 架构设计评估

### 5.1 优点 ✅

1. **模块化设计**：项目结构清晰，分离了配置、服务、路由、模型
2. **代码组织**：使用Flask蓝图，便于扩展
3. **数据库抽象**：使用SQLAlchemy ORM，便于维护
4. **服务层设计**：有独立的服务层，便于业务逻辑复用

### 5.2 需要改进 ⚠️

1. **ORM模型同步**：数据库表已更新，但ORM模型未同步
2. **数据接收缺失**：只有查询接口，缺少数据接收接口
3. **数据处理缺失**：缺少数据清洗、标准化、质量标记等处理逻辑

---

## 6. 改进优先级建议

### 高优先级（P0）

1. **更新ORM模型**：同步数据库表结构到ORM模型
   - `SensorReading` 模型
   - `CameraImage` 模型
   - `ShrimpStats` 模型

2. **创建新表ORM模型**：
   - `batches`
   - `feeders_logs`
   - `operations_logs`
   - `manuals_docs`
   - `history_records`

3. **创建数据接收API端点**：
   - `POST /api/sensors/data` - 传感器数据接收
   - `POST /api/cameras/images` - 图像数据接收
   - `POST /api/feeders/logs` - 喂食机数据接收

### 中优先级（P1）

4. **实现数据清洗服务**：
   - 时间标准化
   - 单位统一
   - 异常值检测

5. **实现数据质量管理**：
   - 质量标记逻辑
   - 完整性校验生成

### 低优先级（P2）

6. **实现数据验收流程**：
   - 自动验收
   - 手动验收界面

7. **实现文档处理**：
   - 文档解析（PDF、Word、Excel）
   - NLP处理

---

## 7. 具体改进方案

### 7.1 更新 SensorReading 模型

```python
# db_models/sensor_reading.py
class SensorReading(Base):
    __tablename__ = "sensor_readings"
    
    # 现有字段
    id: Mapped[int] = ...
    sensor_id: Mapped[int] = ...
    value: Mapped[float] = ...
    recorded_at: Mapped[Optional[TIMESTAMP]] = ...
    
    # 新增字段
    batch_id: Mapped[Optional[int]] = mapped_column(BIGINT UNSIGNED, ...)
    pool_id: Mapped[Optional[str]] = mapped_column(String(64), ...)
    ts_utc: Mapped[Optional[datetime]] = mapped_column(DATETIME(3), ...)
    ts_local: Mapped[Optional[datetime]] = mapped_column(DATETIME(3), ...)
    metric: Mapped[Optional[str]] = mapped_column(String(32), ...)
    type_name: Mapped[Optional[str]] = mapped_column(String(128), ...)
    description: Mapped[Optional[str]] = mapped_column(TEXT, ...)
    unit: Mapped[Optional[str]] = mapped_column(String(50), ...)
    quality_flag: Mapped[str] = mapped_column(ENUM('ok','missing','anomaly'), default='ok', ...)
    checksum: Mapped[Optional[str]] = mapped_column(String(64), ...)
    created_at: Mapped[datetime] = ...
    updated_at: Mapped[datetime] = ...
```

### 7.2 创建数据接收API端点

```python
# routes/data_collection_routes.py
@api_bp.route('/sensors/data', methods=['POST'])
def receive_sensor_data():
    """接收传感器数据"""
    # 1. 接收数据包
    # 2. 格式校验
    # 3. 数据清洗
    # 4. 数据标准化
    # 5. 质量标记
    # 6. 生成校验和
    # 7. 存储到数据库
    pass
```

### 7.3 创建数据清洗服务

```python
# services/data_cleaning_service.py
class DataCleaningService:
    @staticmethod
    def standardize_time(ts: Any) -> Tuple[datetime, datetime]:
        """时间标准化：返回UTC和本地时间"""
        pass
    
    @staticmethod
    def normalize_unit(value: float, from_unit: str, to_unit: str) -> float:
        """单位统一"""
        pass
    
    @staticmethod
    def detect_anomaly(value: float, metric: str, threshold: Dict) -> bool:
        """异常值检测"""
        pass
```

---

## 8. 总结

### 符合度统计

| 类别 | 符合度 | 状态 |
|------|--------|------|
| 数据库模型 | 30% | ❌ 需要更新 |
| 数据收集 | 10% | ❌ 需要实现 |
| 数据处理 | 5% | ❌ 需要实现 |
| 数据验收 | 0% | ❌ 需要实现 |
| **总体** | **15%** | **❌ 不符合** |

### 关键发现

1. **数据库表已更新，但ORM模型未同步**：这是最紧急的问题
2. **缺少数据接收功能**：当前只有查询接口，无法接收新数据
3. **缺少数据处理逻辑**：数据清洗、标准化、质量标记等完全缺失
4. **新表模型缺失**：5个新表都没有对应的ORM模型

### 建议行动

1. **立即行动**：更新ORM模型，使其与数据库表结构一致
2. **短期目标**：实现数据接收API端点和数据清洗服务
3. **中期目标**：实现数据质量管理和验收流程
4. **长期目标**：完善文档处理和NLP功能

---

**报告结束**





